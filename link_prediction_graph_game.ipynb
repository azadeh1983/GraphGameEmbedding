{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl\n",
        "!pip install torch==1.9.1\n",
        "!pip install node2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrvY77v-O630",
        "outputId": "760879b6-a0e1-4ff7-9676-84811ff2af90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting node2vec\n",
            "  Downloading node2vec-0.4.6-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.3.2)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.3.2)\n",
            "Collecting networkx<3.0,>=2.5 (from node2vec)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.25.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.66.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (6.4.0)\n",
            "Installing collected packages: networkx, node2vec\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "Successfully installed networkx-2.8.8 node2vec-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0i9JJPeOqUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5542cf9-8e7d-43d2-bdf4-f1a8e6b88161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import dgl\n",
        "import dgl.data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl.nn import SAGEConv,GCN2Conv\n",
        "import dgl.function as fn\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import sklearn.metrics\n",
        "from node2vec import Node2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score,roc_curve\n",
        "\n",
        "from dgl.nn import GraphConv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load CORA dataset"
      ],
      "metadata": {
        "id": "zz_s0oachlgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "# dataset = dgl.data.CiteseerGraphDataset()\n",
        "# dataset = dgl.data.PubmedGraphDataset()\n",
        "g = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-yulvrMO0z_",
        "outputId": "599ffc10-998e-4590-89e4-7270183f905c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2_d697a464\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "edges of CORA graph\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8GWrvCYQh1kD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u, v = g.edges()"
      ],
      "metadata": {
        "id": "tSciab0kPRyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_ids = np.arange(g.number_of_edges())\n",
        "edge_ids = np.random.permutation(edge_ids)\n",
        "test_size = int(len(edge_ids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[edge_ids[:test_size]], v[edge_ids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[edge_ids[test_size:]], v[edge_ids[test_size:]]"
      ],
      "metadata": {
        "id": "TPi2rUP3PV9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_edge_ids = np.random.choice(len(neg_u), g.number_of_edges() // 2)\n",
        "test_neg_u, test_neg_v = neg_u[neg_edge_ids[:test_size]], neg_v[neg_edge_ids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_edge_ids[test_size:]], neg_v[neg_edge_ids[test_size:]]"
      ],
      "metadata": {
        "id": "Vi2yYyy1PcMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "adjacency matrix of CORA\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CXuF1rxki4sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adj.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6u4Sn6MUVqV",
        "outputId": "0900434a-1878-409f-9d7c-48bff07e0480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2708, 2708)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, edge_ids[:test_size])"
      ],
      "metadata": {
        "id": "URr_-YaPPjMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.add_self_loop(train_g)"
      ],
      "metadata": {
        "id": "M1im2qgMzKyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimal_threshold(tpr, fpr, thresholds):\n",
        "  g_means = tpr*(1-fpr)\n",
        "  max_index = np.argmax(g_means)\n",
        "  return thresholds[max_index]"
      ],
      "metadata": {
        "id": "7vZcui33PoJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize_scores(scores, labels, optimal_threshold):\n",
        "  final_preds = []\n",
        "  for i in range(len(scores)):\n",
        "    if(scores[i]<=optimal_threshold):\n",
        "      final_preds.append(0)\n",
        "    else:\n",
        "      final_preds.append(1)\n",
        "  return np.asarray(final_preds)"
      ],
      "metadata": {
        "id": "dgn-jmzoPsSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, h_feats)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n"
      ],
      "metadata": {
        "id": "LHWXsyL3aNpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "metadata": {
        "id": "bGsDQ420P41e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            #computing score\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return g.edata['score'][:, 0]"
      ],
      "metadata": {
        "id": "hSWMFCqYP8IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=adj\n",
        "s=h"
      ],
      "metadata": {
        "id": "Lw7yAPkLVgkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "#-----------calcuate similarity between two embedding vectors\n",
        "def cal_simi(s1,s2):\n",
        "  dot_product=torch.dot(s1,s2)\n",
        "  norm_product=torch.norm(s1)*torch.norm(s2)\n",
        "  simi=torch.exp(dot_product / norm_product)\n",
        "  return simi\n",
        "\n",
        "#---------------------- calculate U+ -----------------\n",
        "def Uplus(A,s):\n",
        "  Uplus=[]\n",
        "  adj=[]\n",
        "  random_adj=[]\n",
        "  for i in range(len(A)):\n",
        "      U=0\n",
        "      adj=[]\n",
        "      random_adj=[]\n",
        "      for j in A[i].nonzero():\n",
        "        adj.append(j)\n",
        "      if len(adj)>= 5:\n",
        "        random_adj.append(random.sample(adj,5))\n",
        "        random_adj=random_adj[0]\n",
        "      else:\n",
        "        random_adj=adj\n",
        "      if len(random_adj)>0:\n",
        "        for j in random_adj:\n",
        "          # print(i,j)\n",
        "          U+=A[i][j]*cal_simi(s[i],s[j][0])\n",
        "      Uplus.append(U)\n",
        "  return Uplus"
      ],
      "metadata": {
        "id": "IRM8d2lwVgWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "A = A.todense()\n",
        "A=torch.tensor(A)\n",
        "Ak=torch.mm(A,A)\n",
        "Abar=1-Ak\n",
        "Abar[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6IFBqxLVgLF",
        "outputId": "608b002f-7040-48e5-afb8-a00f49c6764a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.,  1.,  1.,  ...,  1.,  1.,  1.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------ calculate U- ---------------------\n",
        "def Umin(A,s):\n",
        "  U=0\n",
        "  Umin=[]\n",
        "  n_adj=[]\n",
        "  random_adj=[]\n",
        "  for i in range(len(A)):\n",
        "    U=0\n",
        "    for j in torch.nonzero(A[i] == 0):\n",
        "        n_adj.append(j)\n",
        "    for j in torch.nonzero(Ak[i] == 0):\n",
        "      if j !=i:\n",
        "        n_adj.append(j)\n",
        "    if len(n_adj)>= 10:\n",
        "        random_adj=random.sample(n_adj,10)\n",
        "        random_adj=random_adj[0]\n",
        "    else:\n",
        "        random_adj=n_adj\n",
        "        random_adj=random_adj[0]\n",
        "    if len(random_adj)>0:\n",
        "        for j in random_adj:\n",
        "          # print(i,j)\n",
        "          if s[j].shape ==torch.Size([1, 2]):\n",
        "            U+=Abar[i][j]*cal_simi(s[i],s[j][0])\n",
        "          else:\n",
        "            U+=Abar[i][j]*cal_simi(s[i],s[j])\n",
        "    Umin.append(U)\n",
        "  return Umin"
      ],
      "metadata": {
        "id": "W-PJy9UwV2Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(train_g.ndata['feat'].shape[1], 128)\n",
        "pred = DotPredictor()\n",
        "\n",
        "def compute_loss(h, pos_score, neg_score):\n",
        "    uplus=Uplus(A,h)\n",
        "    umin=Umin(A,h)\n",
        "    uplus=torch.tensor(uplus)\n",
        "    umin=torch.tensor(umin)\n",
        "    loss=torch.mean(-1*(torch.log(uplus)-torch.log(uplus+umin)))\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return (F.binary_cross_entropy_with_logits(scores, labels)+loss)/2\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores),scores,labels, roc_curve(labels, scores)"
      ],
      "metadata": {
        "id": "siZODPtFQAnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    h = model(train_g, train_g.ndata['feat'])\n",
        "    print(\"h=\",h.shape)\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(h,pos_score, neg_score)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch ',e,' loss: ', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kg-b4tMiQFk0",
        "outputId": "c329e04d-0976-4e55-cfad-70cbca732ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h= torch.Size([2708, 128])\n",
            "In epoch  0  loss:  tensor(0.4680, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  5  loss:  tensor(0.4688, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  10  loss:  tensor(0.4506, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  15  loss:  tensor(0.4485, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  20  loss:  tensor(0.4415, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  25  loss:  tensor(0.4304, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  30  loss:  tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  35  loss:  tensor(0.3950, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  40  loss:  tensor(0.3728, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  45  loss:  tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  50  loss:  tensor(0.3145, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  55  loss:  tensor(0.2870, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  60  loss:  tensor(0.2764, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  65  loss:  tensor(0.2636, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  70  loss:  tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "In epoch  75  loss:  tensor(0.2414, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n",
            "h= torch.Size([2708, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b1562752323e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpos_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pos_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mneg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_neg_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-1939187a0e84>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(h, pos_score, neg_score)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muplus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mumin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0muplus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muplus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mumin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-a33f6b8f5520>\u001b[0m in \u001b[0;36mUmin\u001b[0;34m(A, s)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mn_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrandom_adj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    auc_score, scores, labels, (tpr, fpr, thresholds) = compute_auc(pos_score, neg_score)\n",
        "    opt_threshold = get_optimal_threshold(tpr, fpr, thresholds)\n",
        "    binarized_preds = binarize_scores(scores,labels, opt_threshold)\n",
        "    print('AUC', auc_score)\n",
        "    print(\"accuracy: \",sklearn.metrics.accuracy_score(labels,binarized_preds))\n",
        "    print(\"F-measure: \",sklearn.metrics.f1_score(labels,binarized_preds))\n",
        "    print(\"Precision: \",sklearn.metrics.precision_score(labels,binarized_preds) )\n",
        "    print(\"Recall: \",sklearn.metrics.recall_score(labels,binarized_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q8QvFxrQIyK",
        "outputId": "81dce6ba-8682-4bca-c0c4-4350c8d8c30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC 0.8943114485299072\n",
            "accuracy:  0.7971563981042654\n",
            "F-measure:  0.7857857857857858\n",
            "Precision:  0.8324496288441146\n",
            "Recall:  0.7440758293838863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U5aXOtmzQP4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}